---
layout: post
title: "Stats 1"
categories: [math, ml, data]
tags: [statistics]
math: 1
toc: 1
---

{% assign img-url = '/images/posts/stats' %}

Learn again Stats for Machine Learning and Data Science. A preparation step before writing articles on Math2IT.

{% include toc.html %}

## References

- Book: **Understandable Statistics**- Brase Brase BOOK.pdf
- Book: **Think Stats 2** (with Python) - Allen B. Downey.
- Interactive book: **[Seeing Theory](https://seeing-theory.brown.edu)**.

## Fundamental

### General

<ul class="collapsible" data-collapsible="accordion">
<li>
<div class="collapsible-header" markdown="1"><i class="material-icons">face</i>
Khi nào thì PMF, CDF, PDF? Discrete vs Continuous? ([ref](https://math.stackexchange.com/a/697467/83019))
</div>
<div class="collapsible-body" markdown="1">

**Distribution Function**

 1. The probability distribution function / probability function has ambiguous definition. They may be referred to:
- Probability density function (PDF) 	
- Cumulative distribution function (CDF)
- or probability mass function (PMF) (statement from Wikipedia)
 2. But what confirm is:
- Discrete case: Probability Mass Function (PMF)
- Continuous case: Probability Density Function (PDF)
- Both cases: Cumulative distribution function (CDF)
 3. Probability at certain $x$ value, $P(X = x)$ can be directly obtained in:
- PMF for discrete case
- PDF for continuous case
 4. Probability for values less than $x$, $P(X < x)$ or Probability for values within a range from $a$ to $b$, $P(a < X < b)$ can be directly obtained in:
- CDF for both discrete / continuous case
 5. Distribution function is referred to CDF or Cumulative Frequency Function (see [this](http://mathworld.wolfram.com/DistributionFunction.html))

**In terms of Acquisition and Plot Generation Method**

 1. Collected data appear as discrete when:
- The measurement of a subject is naturally discrete type, such as numbers resulted from dice rolled, count of people.
- The measurement is digitized machine data, which has no intermediate values between quantized levels due to sampling process.
- In later case, when resolution higher, the measurement is closer to analog/continuous signal/variable.
 2. Way of generate a PMF from discrete data:
- Plot a histogram of the data for all the $x$'s, the $y$-axis is the frequency or quantity at every $x$.
- Scale the $y$-axis by dividing with total number of data collected (data size) $\longrightarrow$ and this is called PMF.
 3. Way of generate a PDF from discrete / continuous data:
- Find a continuous equation that models the collected data, let say normal distribution equation.
- Calculate the parameters required in the equation from the collected data. For example, parameters for normal distribution equation are mean and standard deviation. Calculate them from collected data.
- Based on the parameters, plot the equation with continuous $x$-value $\longrightarrow$ that is called PDF.
 4. How to generate a CDF:
- In discrete case, CDF accumulates the $y$ values in PMF at each discrete $x$ and less than $x$. Repeat this for every $x$. The final plot is a monotonically increasing until $1$ in the last $x$ $\longrightarrow$ this is called discrete CDF.
- In continuous case, integrate PDF over $x$; the result is a continuous CDF.

**Why PMF, PDF and CDF?**

1. PMF is preferred when
- Probability at every $x$ value is interest of study. This makes sense when studying a discrete data - such as we interest to probability of getting certain number from a dice roll.
2. PDF is preferred when
- We wish to model a collected data with a continuous function, by using few parameters such as mean to speculate the population distribution.
3. CDF is preferred when
- Cumulative probability in a range is point of interest. 
- Especially in the case of continuous data, CDF much makes sense than PDF - e.g., probability of students' height less than $170$ cm (CDF) is much informative than the probability at exact $170$ cm (PDF).

</div>
</li>
</ul>


### Random Variable (RV)

- A **Random Variable** is a set of possible values from a random experiment. $\Leftarrow$ Chỉ thích hợp với discrete RV mà thôi!
- **Continuous RV** ([ref](https://www.quora.com/What-is-the-difference-between-a-probability-density-function-and-a-cumulative-distribution-function) $\Leftarrow$ good explanation!)
  - If we want to define the probability of an event in which the *random variable takes a specific value*, the probability for *this event will usually be zero* (<mark>vì khoảng là liên tục, chia ra $\infty$ khoảng nên là 0</mark>)
  - Instead, we define the probability of events in which <mark>the random variable takes a value within a specific interval</mark> $\Rightarrow$ We can use CDF (Cumulative Distribution Function).
  - **[??]** **Ví dụ của continuous RV:**  
- The set of possible values is called the **Sample Space**.
- A Random Variable has a whole set of values ... and it could take on any of those values, randomly.
- Ex: X = {0, 1, 2, 3} and X could be 0, 1, 2, or 3 randomly.
- **Probability**: P(X = value) = probability of that value
- Random Variables can be either Discrete or Continuous:


### Mean - Median - Mode

- Có sự khác biệt giữa rời rạc và liên tục (continuous probability distribution).
- Nếu rời rạc thì dễ hiểu rồi.
- Nếu liên tục: 
  - **Mean**: Cái giúp cân bằng ếu để trên 1 cái tam giác.
  - **Median**: Cái chia đôi diện tích.
  - **Mode**: Cái cao nhất!

### Expected value & Variance

Có thể tham khảo interactive prob [tại đây](https://seeing-theory.brown.edu/basic-probability/index.html).

**Expected value** = Mean = (intuitively) the <mark>long-run average of occurrences</mark>.
- *Discrete*: $\mu = E(X) = \Sigma[xP(x)]$
- *Continuous*: $\mu=E(X) = \int\_{\mathbb{R}} xf\_X(x) dx$ where $f\_X$ is PDF (probability density function)

**[??]**: **Hiểu công thức của Continuous như thế nào?** (Discrete thì dễ rồi, nó là *weight\*value* thôi).
  - Trước hết phải hiểu PDF là gì? (Xem bên dưới)
  - Sau khi hiểu $f\_X$ rồi thì $f\_X(x)$ cũng là xác suất của $X$ tại $x$ ($P(X=x)$).

**Variance** = Whereas expectation provides a measure of centrality, the variance of a random variable quantifies the <mark>spread of that random variable</mark>'s distribution.
  - Tưởng tượng nó giống trung bình khoảng cách khác biệt giữa $\bar{y}$ và $y$.

  $$
  \text{Var}(X) = \text{E}[(X - \text{E}[X])^2]
  $$

### Probability mass function (PMF)

- [Good explanation](https://www.quora.com/What-is-the-difference-between-a-probability-density-function-and-a-cumulative-distribution-function).
- The probability distribution of a **discrete** random variable is called the **probability function** or the **probability mass function** (aka PMF).

  $$
  p_X(x) = P(X=x)
  $$

- Properties:
  - $0\le p\_X(x) \le 1$.
  - $\Sigma\_x p\_X(x)=1$.

### Cumulative distribution function (CDF)

- The CDF of a real-valued random variable X, or just distribution function of X, evaluated at x, is the probability that X will take a value less than or equal to x.
  - **Cummylative** = lũy tích -> tích lũy xác suất cho đến $x$.
  - Discrete ($\Sigma$), continuous ($\int$).

  $$
  \begin{align}
  F_X(x) &= P(X\le x) = (\Sigma_{t\le x}f(t)) = (\int_{-\infty}^xf_X(t)dt). \\
  P(a<X\le b) &= F_X(b) - F_X(a). \\
  \bar{F}_X(x) &= P(X>x) = 1-F_X(x).
  \end{align}
  $$

- **Properties**:
  - $0 \le F\_X(x) \le 1$
  - CDF a *non-decreasing function*, or *monotonically increasing* because we are adding up the probabilities for each outcome.
  - CDF is said to be a continuous function, (it has no "holes" in the graph)
  - $\lim\_{x\to -\infty}F\_X(x)=0$, $\lim\_{x\to +\infty}F\_X(x)=1$

- **Question** - Tại sao $a<X$ mà không phải là $a\le X$? -> tại vì nó đã bị trừ trong cái $-F\_X(a)$.
- Dấu "=" chỉ quan trọng với discrete variable, continuous variable không quan trọng lắm!


### Probability density function (PDF)

- PDF or **density** of a continuous random variable: <mark>$f\_X(x)$</mark>
- The PDF is used to <mark>specify the probability of the random variable</mark> falling within a particular range of values
  - Its value at any given point is actually meaningless: trên khoảng thì có xác suất là $\int$ trên khoảng đó nhưng tại 1 điểm thì ko có xác suất (nếu xét theo ý tưởng chia cho $\infty$ miền nhỏ)! **Tuy nhiên**, ta vẫn có thể tính xác suất của 1 biến continuous X tại 1 điểm: <mark>$P(X=x) = f(x)$</mark>.
- **Properties**:
  - $f\_X(x) = \frac{dF\_X(x)}{dx}$
- Relationship between a PDF (hình trên) and the CDF (hình dưới). [Ref](https://www.internalpointers.com/post/cumulative-distribution-function-cdf).
  - CDF $\Rightarrow$ trên graph chỉ là tại 1 điểm nhưng giá trị thật ra là trên 1 khoảng (trên PMF hoặc PDF)
  - PDF $\Rightarrow$ diện tích của 1 dãy tới điểm đang xét / tổng diện tích!

  ![Relationship betwee a PDF and a CDF]({{img-url}}/pdf-cdf.jpg){:.w-300}
- Other ideas/explanation: [[mathinsight](https://mathinsight.org/probability_density_function_idea)]

## Distributions

### Normal distribution

- Bài viết hay: [mathisfun](https://www.mathsisfun.com/data/standard-normal-distribution.html)
- Bài viết chi tiết khác: [file](https://www.westga.edu/academics/research/vrc/assets/docs/the_normal_distribution_notes.pdf) (đã backup ở *the\_normal\_distribution\_notes.pdf*)
- Đặc trưng: mean ($\mu$) and standard deviation ($\sigma$)
- Nếu một biến ngẫu nhiên X có phân phối chuẩn thì: $X\sim \mathcal{N}(\mu, \sigma)$.
- Ví dụ của "**not** a normal distribution": [xúc xắc](https://brilliant.org/wiki/central-limit-theorem/), điểm thi của học sinh lớp 9 khi làm đề lớp 8.
- **[68-95-99.7 rule](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule)**
  - 68% ($\mu-\sigma, \mu+\sigma$), 95% ($\mu-2\sigma, \mu+2\sigma$), 99.7% ($\mu-3\sigma, \mu+3\sigma$)
  - Tại sao giữa $(0,\delta)$ thì là 34.1% nhưng giữa $(-\delta, \delta$) lại là 68%? $\Rightarrow$ Chỉ là xấp xỉ mà thôi (để có cái tên gọn gọn của [68-95-99.7 rule](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule))

### Binomial distribution



## Central Limit Theorem

- Định lý giới hạn trung tâm.
- Def (ref to [brilliant](https://brilliant.org/wiki/central-limit-theorem/)): The central limit theorem is a theorem about **independent random variables**, which says roughly that the probability distribution of the average of independent random variables will **converge to a normal distribution**, as the number of observations increases. The somewhat surprising strength of the theorem is that (under certain natural conditions) there is essentially no assumption on the probability distribution of the variables themselves; the **theorem remains true no matter what the individual probability distributions are**.





